{"name":"Courier","tagline":"Scala data binding generator for multiple data formats including JSON and Avro.","body":"Courier\r\n=======\r\n\r\nCourier generates Scala idiomatic data bindings from schemas.\r\n\r\nCourier generated bindings work with multiple data formats including JSON and\r\n[Avro](http://avro.apache.org/).\r\n\r\n* [Source](http://github.com/coursera/courier)\r\n* [Documentation](https://github.com/coursera/courier/wiki)\r\n* [Discussion Group](https://groups.google.com/d/forum/courier)\r\n\r\nOverview\r\n--------\r\n\r\nCourier is a language binding for Scala for the\r\n[Pegasus](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates) schema and data\r\nsystem, part of the [Rest.li](http://rest.li) umbrella project.\r\n\r\nPegasus contains an expressive schema language for JSON structured data that is based on the Avro\r\nschema language, but adds optional fields a few other conveniences to make it easy to define the\r\nstructure of natural looking JSON. Pegasus also has a rich feature set including schema\r\nbased validation, data translation between multiple data formats, schema compatibility with\r\nAvro, and generated Java data bindings.\r\n\r\nBy using Courier, all the features of Pegasus can be leveraged by Scala developers but with\r\nScala idiomatic data bindings that look and feel natural to a Scala developer.\r\n\r\nFeatures\r\n--------\r\n\r\n* Scala Idiomatic Data Binding Generator\r\n* [SBT Plugin](https://github.com/coursera/courier#getting-started)\r\n* [Gradle Plugin](https://github.com/coursera/courier/tree/master/gradle-plugin)\r\n* Data and Schema Compatible with [Pegasus](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates)\r\n* Data and Schema Compatible with [Avro](http://avro.apache.org/)\r\n* Support for multiple \"Data Codecs\", including JSON, PSON, and Avro binary\r\n\r\nGetting Started\r\n---------------\r\n\r\nHere we setup a simple SBT project with Courier. If you use Gradle instead of SBT, see the\r\n[Gradle Plugin](https://github.com/coursera/courier/tree/master/gradle-plugin) documentation.\r\n\r\nAdd the generator dependencies to your SBT plugins:\r\n\r\n`project/plugins.sbt`:\r\n\r\n```scala\r\naddSbtPlugin(\"org.coursera.courier\" % \"courier-sbt-plugin\" % \"0.4.1\")\r\n```\r\n\r\nEnable the generator to SBT build:\r\n\r\n`project/Build.scala`:\r\n\r\n```scala\r\nimport sbt._\r\nimport Keys._\r\nimport org.coursera.courier.sbt.CourierPlugin._\r\n\r\nobject Example extends Build {\r\n\r\n  val courierVersion = \"0.4.1\"\r\n\r\n  lazy val example = Project(\"example\", file(\"example\"))\r\n    .dependsOn(schemas)\r\n    .aggregate(schemas)\r\n    // ...\r\n\r\n  lazy val schemas = Project(\"schemas\", file(\"schemas\"))\r\n    .settings(courierSettings: _*)\r\n    .settings(libraryDependencies += \"org.coursera.courier\" %% \"courier-runtime\" % courierVersion)\r\n}\r\n```\r\n\r\nAdd `.pdsc` files to the `src/main/pegasus` directory of your project. For example:\r\n\r\n`schemas/src/main/pegasus/org/example/fortune/Fortune.pdsc`:\r\n\r\n```json\r\n{\r\n  \"name\": \"Fortune\",\r\n  \"namespace\": \"org.example.fortune\",\r\n  \"type\": \"record\",\r\n  \"fields\": [\r\n    { \"name\": \"message\", \"type\": \"string\" }\r\n  ]\r\n}\r\n\r\n```\r\n\r\nIn SBT, run:\r\n\r\n```sh\r\nproject example\r\ncompile\r\n```\r\n\r\nWhen run, the `org.example.fortune.Fortune` Scala class is generated. It behaves the same as\r\na case class, but can be serialized to JSON, or any other data format a Pegasus codec is available\r\nfor.  For example:\r\n\r\n`example/src/main/scala/Main.scala`:\r\n\r\n```scala\r\nimport com.linkedin.data.template.PrettyPrinterJacksonDataTemplateCodec\r\nimport org.example.fortune.Fortune\r\n\r\nobject Example extends App {\r\n  val fortune = Fortune(message = \"Today is your lucky day!\")\r\n\r\n  val codec = new PrettyPrinterJacksonDataTemplateCodec\r\n  println(codec.mapToString(fortune.dataMap))\r\n  // -> { \"message\": \"Today is your lucky day!\" }\r\n}\r\n```\r\n\r\nThe generator is run automatically before `src/main/scala` compilation. It also registers for\r\ntriggered execution to support SBT commands like `~compile`, which will cause the generator to\r\nrun immediately whenever a .pdsc file is changed.\r\n\r\nThe generator will write Scala files to the `target/scala-<scalaMajorVersion>/courier` directory of\r\nyour project and add them to the compile classpath.\r\n\r\nFor details on the `.pdsc` file format, see\r\n[Pegasus Schemas and Data](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates).\r\n\r\nThe code generator is an extension of the Rest.li SBT Plugin, for more details, see\r\n[the rest.li-sbt-plugin wiki](https://github.com/linkedin/rest.li-sbt-plugin).\r\n\r\n#### Testing\r\n\r\n`.pdsc` files only needed for tests may be added to `src/test/pegasus`.\r\n\r\nRecord Types\r\n------------\r\n\r\n[Pegasus Records](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#record-type)\r\ncontain any number of fields, which may be any pegasus type, including\r\nprimitives, enums, unions, maps and arrays.\r\n\r\nFor example, a basic record type containing a few fields:\r\n\r\n```json\r\n{\r\n  \"name\": \"Example\",\r\n  \"namespace\": \"org.example\",\r\n  \"doc\": \"A simple record.\",\r\n  \"type\": \"record\",\r\n  \"fields\": [\r\n    { \"name\": \"field1\", \"type\": \"string\" },\r\n    { \"name\": \"field2\", \"type\": \"int\", \"optional\": true }\r\n  ]\r\n}\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\n/** A simple record */\r\ncase class Example(field1: String, field2: Option[Int])\r\n```\r\n\r\n[Record Fields](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#record-field-attributes)\r\nmay be optional and/or may have default values.\r\n\r\nSchema Field                                 | Generated Scala\r\n---------------------------------------------|------------------------------------------------------\r\n`\"type\": \"string\"`                           | `case class Record(field: String)`\r\n`..., \"default\": \"message\"`                  | `case class Record(field: String = \"message\")`\r\n`..., \"optional\": true`                      | `case class Record(field: Option[String])`\r\n`..., \"optional\": true \"default\": \"message\"` | `case class Record(field: Option[String] = Some(\"message\"))`\r\n`..., \"optional\": true, \"defaultNone\": true` | `case class Record(field: Option[String] = None)`\r\n\r\nNote that `\"defaultNone\"` is not part of Pegasus, but is a custom property supported by Courier\r\nspecifically added it make it possible to generate idiomatic Scala bindings.\r\n\r\nSchema fields may also be documented or marked as deprecated:\r\n\r\nSchema Field                                 | Generated Scala\r\n---------------------------------------------|------------------------------------------------------\r\n`..., \"doc\": \"A documented field\"`           | `case class Record(/** A documented field */ field: String)`\r\n`..., \"deprecated\": \"Use field X instead\"`   | `case class Record(@deprecated(message = \"Use field X instead\") field: String)`\r\n\r\nRecords may [include fields from other records](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#including-fields-from-another-record)\r\nusing `\"include\"`:\r\n\r\n```scala\r\n{\r\n  \"name\" : \"WithIncluded\",\r\n  \"type\" : \"record\",\r\n  \"include\" : [ \"Foo\" ],\r\n  \"fields\" : [ ... ]\r\n}\r\n```\r\n\r\nIn pegasus, field inclusion does not imply inheritance, it is merely a\r\nconvenience to reduce duplication when writing schemas.\r\n\r\n#### Record Backward Compatibility\r\n\r\nThe backward compatibility rules for records are:\r\n\r\nCompatible changes:\r\n\r\n* Adding an optional fields\r\n* Adding a field with a default (required or optional)\r\n\r\nWhen accessing fields:\r\n\r\n* Unrecognized fields must be ignored.\r\n* Fields with defaults should always be written, either with the desired value or\r\n  the default value.\r\n* The default value for a field should be assumed if the field is absent and is\r\n  needed by the reader.\r\n\r\nPrimitive Types\r\n---------------\r\n\r\nThe [Pegasus primitive](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#primitive-types)\r\ntypes are: int, long, float, double, boolean, string and bytes.\r\n\r\nSchema Type | Scala Type    | Example JSON data\r\n------------|---------------|------------------\r\n\"int\"       | Int           | 100\r\n\"long\"      | Long          | 10000000\r\n\"float\"     | Float         | 3.14\r\n\"double\"    | Double        | 2.718281\r\n\"boolean\"   | Boolean       | true\r\n\"string\"    | String        | \"coursera\"\r\n\"bytes\"     | ByteString    | \"\\u0001\\u0002\"\r\n\r\nA 'null' type also exists, but should generally be avoided in favor of optional fields.\r\n\r\nArray Type\r\n----------\r\n\r\n[Pegasus Arrays](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#array-type)\r\nare defined with a `items` type using the form:\r\n\r\n```json\r\n{ \"type\": \"array\", \"items\": \"org.example.Fortune\" }\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\nclass FortuneArray extends IndexedSeq[Fortune]\r\n```\r\n\r\nFor example, to define a field of a record containing an array, use:\r\n\r\n```json\r\n{\r\n  \"name\": \"Fortune\",\r\n  \"namespace\": \"org.example.fortune\",\r\n  \"type\": \"record\",\r\n  \"fields\": [\r\n    { \"name\": \"arrayField\", \"type\": { \"type\": \"array\", \"items\": \"int\" } }\r\n  ]\r\n}\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\ncase class Fortune(arrayField: IntArray)\r\n```\r\n\r\nArray items may be any pegasus type.\r\n\r\nThe array types for all primitive value types (`IntArray`, `StringArray`, ...) are pre-generated by Courier and\r\nprovided in the `courier-runtime` artifact in the `org.coursera.courier.data` package. The generator\r\nis aware of these classes and will refer to them instead of generating them when primitive arrays are used.\r\n\r\nSchema type                                         | Scala type\r\n----------------------------------------------------|--------------------------------------------------\r\n`{ \"type\": \"array\", \"items\": \"int\" }`               | `org.coursera.courier.data.IntArray` (predefined)\r\n`{ \"type\": \"array\", \"items\": \"org.example.Record\" }`| `org.example.RecordArray` (generated)\r\n\r\nAll generated Arrays implement Scala's `IndexedSeq`, `Traversable` and `Product` traits and behave\r\nlike a standard Scala collection type.\r\n\r\n```scala\r\nval array = IntArray(10, 20, 30)\r\n\r\narray(0)\r\n\r\narray.map { int => ... }\r\n\r\narray.zipWithIndex\r\n\r\narray.filter(_ > 20)\r\n\r\narray.toSet\r\n```\r\n\r\nUnsurprisingly, Pegasus arrays are represented in JSON as arrays.\r\n\r\nScala Expression                                  | Equivalent JSON data\r\n--------------------------------------------------|------------------------------------\r\nIntArray(1, 2, 3)                                 |`[1, 2, 3]`\r\nRecordArray(Record(field = 1), Record(field = 2)) |`[ { \"field\": 1 }, { \"field\": 2 } ]`\r\n\r\n\r\nOrdinarily, arrays are defined inline inside other types. But if needed,\r\ntyperefs allow a map to be defined in a separate .pdsc file and be assigned a\r\nunique type name. See below for more details about typerefs.\r\n\r\nMap Type\r\n--------\r\n\r\n[Pegasus Maps](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#map-type)\r\nare defined with a `values` type, and an optional `keys` type, using the form:\r\n\r\n```json\r\n{ \"type\": \"map\", \"keys\": \"int\", \"values\": \"org.example.Fortune\" }\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\nclass IntToFortuneMap extends Map[Int, Fortune]\r\n```\r\n\r\nIf no \"keys\" type is specified, the key type will default to \"string\". For example:\r\n\r\n```json\r\n{ \"type\": \"map\", \"values\": \"org.example.Note\" }\r\n```\r\n\r\nwill be generated as:\r\n\r\n```scala\r\nclass NoteMap extends Map[String, Note]\r\n```\r\n\r\nWhen complex types are used for \"keys\", [InlineStringCodec](https://github.com/coursera/courier/blob/master/runtime/src/main/scala/org/coursera/courier/codecs/InlineStringCodec.scala#L38)\r\nis used to serialize/deserialize complex type keys to JSON strings.\r\n\r\nTo define a field of a record containing a map, use:\r\n\r\n```json\r\n{\r\n  \"name\": \"Fortune\",\r\n  \"namespace\": \"org.example.fortune\",\r\n  \"type\": \"record\",\r\n  \"fields\": [\r\n    { \"name\": \"mapField\", \"type\": { \"type\": \"amp\", \"values\": \"int\" } }\r\n  ]\r\n}\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\ncase class Fortune(mapField: IntMap)\r\n```\r\n\r\nLike arrays, map values can be of any type, and the map types for all primitives\r\nare predefined.\r\n\r\nSchema type                                                                        | Scala type\r\n-----------------------------------------------------------------------------------|------------------------------------------------\r\n`{ \"type\": \"map\", \"values\": \"int\" }`                                               | `org.coursera.courier.data.IntMap` (predefined)\r\n`{ \"type\": \"map\", \"values\": \"org.example.Record\" }`                                | `org.example.RecordMap` (generated)\r\n`{ \"type\": \"map\", \"keys\": \"org.example.SimpleId\", \"values\": \"org.example.Record\" }`| `org.example.SimpleIdToRecordMap` (generated)\r\n\r\nAll generated Maps implement Scala's `Map` and `Iterable` traits and behave\r\nlike a standard Scala collection type.\r\n\r\n```scala\r\nval map = IntMap(\"a\" -> 1, \"b\" -> 2, \"c\" -> 3)\r\n\r\nmap.get(\"a\")\r\n\r\nmap.getOrElse(\"b\", 0)\r\n\r\nmap.contains(\"c\")\r\n\r\nmap.mapValues { v => ... }\r\n\r\nmap.filterKeys { _.startsWith(\"a\") }\r\n```\r\n\r\nMaps are represented in JSON as objects:\r\n\r\nScala Expression                                              | Equivalent JSON data\r\n--------------------------------------------------------------|--------------------------------------------\r\nIntMap(\"a\" -> 1, \"b\" -> 2, \"c\" -> 3)                          |`{ \"a\": 1, \"b\": 2, \"c\": 3 }`\r\nRecordMap(\"a\" -> Record(field = 1), \"b\" -> Record(field = 2)) |`{ \"a\": { \"field\": 1 }, \"b\": { \"field\": 2 } }`\r\nSimpleIdToRecordMap(SimpleId(id = 1000) -> Record(field = 1)) |`{ \"(id~1000)\": { \"field\": 1 } }`\r\n\r\n\r\nOrdinarily, maps are defined inline inside other types. But if needed,\r\ntyperefs allow a map to be defined in a separate .pdsc file and be assigned a\r\nunique type name name. See below for more details about typerefs.\r\n\r\nUnion Type\r\n----------\r\n\r\n[Pegasus Unions](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#union-type)\r\n are [tagged union](http://en.wikipedia.org/wiki/Tagged_union) types.\r\n\r\nA union type may be defined with any number of member types.  Each member may be any pegasus\r\ntype except union: primitive, record, enum, map or array.\r\n\r\nUnions types are defined in using the form:\r\n\r\n```json\r\n[ \"<MemberType1>\", \"<MemberType2>\" ]\r\n```\r\n\r\nFor example, a union that holds an `int`, `string` or a `Fortune`\r\nwould be defined as:\r\n\r\n```json\r\n[ \"int\", \"string\", \"org.example.Fortune\" ]\r\n```\r\n\r\nThe member type names also serve as the \"member keys\" (sometimes called \"union tags\"),\r\nand identify which union member type data holds.\r\n\r\nFor example:\r\n\r\nSchema type           | Member key            | Example JSON data\r\n----------------------|-----------------------|---------------------------------------------\r\n\"int\"                 | \"int\"                 | `{ \"int\": 1 }`\r\n\"string\"              | \"string\"              | `{ \"string\": \"coursera\" }`\r\n\"org.example.Fortune\" | \"org.example.Fortune\" | `{ \"org.example.Fortune\": { \"message\": \"Today is your lucky day!\" }`\r\n\r\nLet's look at an example of a union in use.  To define a field of a record containing a\r\nunion of two other records, we would define:\r\n\r\n```json\r\n{\r\n  \"name\": \"Question\",\r\n  \"namespace\": \"org.example\",\r\n  \"type\": \"record\",\r\n  \"fields\": [\r\n    { \"name\": \"answerFormat\", \"type\": [ \"MultipleChoice\", \"TextEntry\" ] }\r\n  ]\r\n}\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\ncase class Question(answerFormat: Question.AnswerFormat)\r\n\r\nobject Question {\r\n  // ...\r\n\r\n  sealed abstract class AnswerFormat()\r\n  case class MultipleChoiceMmeber(value: MultipleChoice) extends AnswerFormat\r\n  case class TextEntryMember(value: TextEntry) extends AnswerFormat\r\n  case class $UnknownMember() extends AnswerFormat // for backward compatibility (see below)\r\n}\r\n```\r\n\r\nHere, because the union was defined inline in in the Question record, it is\r\ngenerated as a class scoped within Question type.\r\nIt is also assigned a name based on the field is is contained in.\r\n\r\nIf the union were instead defined with a typeref it would be assigned the name\r\nof the typeref and be generated as a top level type. This will be covered\r\nin more detail later.\r\n\r\nNote that each member type is \"boxed\" in a `<Type>Member` case class. This is\r\nbecause Scala does not (yet) support disjoint types directly in the type system.\r\n\r\nHere's how the `AnswerFormat` union can be used to create a new `Question`:\r\n\r\nScala Expression                                     | Equivalent JSON data\r\n-----------------------------------------------------|-----------------------------------------------------\r\n`Question(TextEntryMember(TextEntry(...)))`           | `{ \"answerFormat\": { \"org.example.TextEntry\": { ... } } }`\r\n`Question(MultipleChoiceMmeber(MultipleChoice(...)))` | `{ \"answerFormat\": { \"org.example.MultipleChoice\": { ... } }}`\r\n\r\nTo read the union, pattern matching may be used, e.g.:\r\n\r\n```scala\r\nquestion.answerFormat match {\r\n  case TextEntryMember(textEntry) => ...\r\n  case MultipleChoiceMember(multipleChoice) => ...\r\n  case $UnknownMember => ... // for backward compatibility (see below)\r\n}\r\n```\r\n\r\nBecause the union is defined using a sealed base type, Scala can statically\r\ncheck that the cases used are exhaustive.\r\n\r\nThe member key of primitives, maps, arrays and unions are the same as their type name:\r\n\r\n Scala Expression                         | Equivalent JSON data\r\n------------------------------------------|-------------------------\r\n`Record(field = IntMember(1))`                    | `{ \"field\": { \"int\": 1 } }`\r\n`Record(field = StringMember(\"a\"))`               | `{ \"field\": { \"string\": \"a\" } }`\r\n`Record(field = IntMapMember(IntMap(\"a\" -> 1)))`  | `{ \"field\": { \"map\": { \"a\": 1 } } }`\r\n`Record(field = IntArrayMember(IntArray(1,2,3)))` | `{ \"field\": { \"array\": [1, 2, 3] } }`\r\n\r\nOrdinarily, unions are defined inside other types. But if needed,\r\ntyperefs may be used to define a union in a separate .pdsc file and give the union\r\nany desired name. See below for more details about typerefs.\r\n\r\n#### Union Backward Compatibility\r\n\r\n`$UnknownMember` indicates an unrecognized union member was read\r\nfrom serialized data. `$UnknownMember` is primarily intended to ease\r\nmanaging backward compatibility in systems where reader and writers of the data\r\nmay be using different versions of a schema, because, in such system, a reader might\r\nreceive data containing union members they do not yet recognize.\r\n\r\nNote that the presence of the `$UnknownMember` symbol does not, by itself, guarantee\r\nthat adding an a member to the a union is backward compatible. In order to ensure\r\nthis, one must be sure that all readers of the union\r\nhandle reading the `$UnknownMember` in a backward compatible way. Depending on\r\nthe semantic meaning of the union, this may or may not be possible, and so\r\nthe backward compatibility of changes to union members should be approached\r\nwith care.\r\n\r\nEnum Type\r\n---------\r\n\r\n[Pegasus enums](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#enum-type)\r\n\r\nEnums types may contain any number of symbols, for example:\r\n\r\n```json\r\n{\r\n  \"type\" : \"enum\",\r\n  \"name\" : \"Fruits\",\r\n  \"namespace\" : \"org.example\",\r\n  \"symbols\" : [\"APPLE\", \"BANANA\", \"ORANGE\"]\r\n}\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\nobject Fruits extend Enumeration\r\n```\r\n\r\nwhere symbols are referenced as:\r\n\r\n```scala\r\nFruits.APPLE\r\n```\r\n\r\nand the enum's Scala type is:\r\n\r\n```scala\r\nFruits.Fruits\r\n```\r\n\r\nEnums are referenced in other schemas either by name, e.g.:\r\n\r\n```json\r\n{\r\n  \"type\": \"record\",\r\n  \"name\": \"FruitBasket\",\r\n  \"namespace\": \"org.example\",\r\n  \"fields\": [\r\n    { \"name\": \"fruit\", \"type\": \"org.example.Fruits\" }\r\n  ]\r\n}\r\n```\r\n\r\n..or by inlining their type definition, e.g.:\r\n\r\n```json\r\n{\r\n  \"type\": \"record\",\r\n  \"name\": \"FruitBasket\",\r\n  \"namespace\": \"org.example\",\r\n  \"fields\": [\r\n    {\r\n      \"name\": \"fruit\",\r\n      \"type\": {\r\n        \"type\": \"enum\",\r\n        \"name\": \"Fruits\",\r\n        \"symbols\": [\"APPLE\", \"BANANA\", \"ORANGE\"]\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nThis fully generated enum looks like:\r\n\r\n```scala\r\nobject Fruits extends Enumeration {\r\n  type Fruits = Value\r\n\r\n  val APPLE = Value(\"APPLE\")\r\n  val BANANA = Value(\"BANANA\")\r\n  val ORANGE = Value(\"ORANGE\")\r\n\r\n  val $UNKNOWN = Value(\"$UNKNOWN\") // for backward compatibility (see below)\r\n}\r\n```\r\n\r\nEnums are represented in JSON as strings, e.g. `\"APPLE\"`\r\n\r\n#### Enum Backward Compatibility\r\n\r\n`$UNKNOWN` indicates an unrecognized symbol was\r\nread from serialized data. `$UNKNOWN` is primarily intended to ease\r\nmanaging backward compatibility in systems where reader and writers of the data\r\nmay be using different versions of a schema, because, in such system, a reader might\r\nreceive data containing enum symbols they do not yet recognize.\r\n\r\nNote that the presence of the `$UNKNOWN` symbol does not, by itself, guarantee\r\nthat adding an a symbol to the enum is backward compatible. In order to ensure\r\nthis, one must be sure that all readers of the enum\r\nhandle the `$UNKNOWN` symbol in a backward compatible way. Depending on\r\nthe semantic meaning of the enum, this may or may not be possible, and so\r\nthe backward compatibility of changes to enum symbols should be approached\r\nwith care.\r\n\r\nTyperefs\r\n--------\r\n\r\n[Pegasus Typerefs](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#typeref)\r\nprovide a lightweight alias to any other type.\r\n\r\nThey can be used for a variety of purposes. A few common uses:\r\n\r\n(1) Provide a name for a union, map, or array so that it can be referenced by name. E.g.:\r\n\r\n```json\r\n{\r\n  \"name\": \"AnswerTypes\",\r\n  \"namespace\": \"org.example\",\r\n  \"type\": \"typeref\",\r\n  \"ref\": [\"MutlipleChoice\", \"TextEntry\"]\r\n}\r\n\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\nabstract class AnswerTypes\r\ncase class MutlipleChoiceMember(value: MutlipleChoice) extends AnswerTypes\r\ncase class TextEntryMember(value: TextEntry) extends AnswerTypes\r\n```\r\n\r\nAnd can be referred to from any other type using the name\r\n`org.example.AnswerTypes`, e.g.:\r\n\r\n```json\r\n{\r\n  \"type\": \"record\",\r\n  \"name\": \"Question\",\r\n  \"namespace\": \"org.example\",\r\n  \"fields\": [\r\n    { \"name\": \"answerFormat\", \"type\": \"org.example.AnswerTypes\" }\r\n  ]\r\n}\r\n```\r\n\r\nThis is particularly useful because unions, maps and arrays cannot otherwise be\r\nnamed directly like records and enums can.\r\n\r\n(2) Provide additional clarity when using primitive types for specific purposes.\r\n\r\n```json\r\n{\r\n  \"name\": \"UnixTimestamp\",\r\n  \"namespace\": \"org.example\",\r\n  \"type\": \"typeref\",\r\n  \"ref\": \"long\"\r\n}\r\n```\r\n\r\nNo classes will be generated for this typeref. In Scala, typerefs to primitives\r\nare simply bound to their reference types (unless the typref is defined as a\r\ncustom, see below for details).  E.g. `UnixTypestamp` will simply be bound\r\nto `Long` in Scala.\r\n\r\nCustom Types\r\n------------\r\n\r\n[Pegasus Custom Types](https://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#custom-java-class-binding-for-primitive-types)\r\nallow any Scala type to be bound to any pegasus primitive type.\r\n\r\nFor example, [Joda time](http://www.joda.org/joda-time/) has a convenient\r\n`DateTime` class. If we wish to use this class in Scala to represent date times,\r\nall we need to do is define a pegasus custom type that binds to it:\r\n\r\n```json\r\n{\r\n  \"name\": \"DateTime\",\r\n  \"namespace\": \"org.example\",\r\n  \"type\": \"typeref\",\r\n  \"ref\": \"string\",\r\n  \"doc\": \"ISO 8601 date-time.\",\r\n  \"scala\": {\r\n    \"class\": \"org.joda.time.DateTime\",\r\n    \"coercerClass\": \"org.coursera.models.common.DateTimeCoercer\"\r\n  }\r\n}\r\n\r\n```\r\n\r\nThe coercer is responsible for converting the pegasus \"referenced\" type, in this\r\ncase `\"string\"` to the Joda `DateTime` class:\r\n\r\n```scala\r\nclass DateTimeCoercer extends DirectCoercer[DateTime] {\r\n  override def coerceInput(obj: DateTime): AnyRef = {\r\n    DateTimeCoercer.iso8601Format.print(obj)\r\n  }\r\n  override def coerceOutput(obj: Any): DateTime = {\r\n    obj match {\r\n      case string: String => DateTimeCoercer.iso8601Format.parseDateTime(string)\r\n      case _: Any => // ...\r\n    }\r\n  }\r\n}\r\nobject DateTimeCoercer {\r\n  registerCoercer()\r\n  def registerCoercer(): Unit = {\r\n    Custom.registerCoercer(new DateTimeCoercer, classOf[DateTime])\r\n  }\r\n  val iso8601Format = ISODateTimeFormat.dateTime()\r\n}\r\n\r\n```\r\n\r\nOnce a custom type is defined, it can be used in any type. For example, to use the DateTime\r\ncustom type in a record:\r\n\r\n```json\r\n{\r\n  \"type\": \"record\",\r\n  \"name\": \"Fortune\",\r\n  \"namespace\": \"org.example\",\r\n  \"fields\": [\r\n    { \"name\": \"createdAt\", \"type\": \"org.example.DateTime\" }\r\n  ]\r\n}\r\n```\r\n\r\nThis will be generated as:\r\n\r\n```scala\r\ncase class Fortune(createdAt: org.joda.time.DateTime)\r\n```\r\n\r\nJSON serialization/deserialization\r\n----------------------------------\r\n\r\nAll of the pegasus complex types may be serialized using:\r\n\r\n```scala\r\nval fortune = Fortune(message = \"Today is your lucky day!\")\r\nval json = DataTemplates.writeDataMap(fortune.data()) // or writeDataList\r\n```\r\n\r\nAnd deserialized using:\r\n\r\n```scala\r\nval dataMap = DataTemplates.readDataMap(json) // or readDataList\r\nval fortune = Fortune(dataMap, DataConversion.SetReadOnly) // or DataConversion.DeepCopy\r\n```\r\n\r\nCodecs\r\n------\r\n\r\nPegasus and Courier provides multiple \"Codecs\":\r\n\r\n* JacksonDataCodec - The primary JSON encoding used by Pegasus.\r\n* [InlineStringCodec](https://github.com/coursera/courier/blob/master/runtime/src/main/scala/org/coursera/courier/codecs/InlineStringCodec.scala#L38)\r\n  - URL \"Friendly\" string encoding of data.\r\n* [PsonDataCodec](https://github.com/linkedin/rest.li/blob/master/data/src/main/java/com/linkedin/data/codec/PsonDataCodec.java#L41) - Non-standard \"performance\" optimized JSON-like codec.\r\n* BsonDataCodec - The [bson](http://bsonspec.org/) binary encoding for JSON-like data.\r\n\r\nExample codec use:\r\n\r\n```\r\nval codec = new InlineStringCodec()\r\n\r\n// deserialize\r\nval dataMap = codec.bytesToMap(\"(key~value)\".getBytes(Charset.forName(\"UTF-8\"))\r\n\r\n// serialize\r\nval string = new String(codec.mapToBytes(dataMap, Charset.forName(\"UTF-8\")))\r\n```\r\n\r\nAll codecs also support input and output streams, e.g.:\r\n\r\n```\r\nval codec = PsonDataCodec()\r\n\r\n// deserialize\r\nval dataMap = codec.readMap(inputStream)\r\n\r\n// serialize\r\ncodec.writeMap(dataMap, outputStream)\r\n```\r\n\r\nAvro Translators\r\n----------------\r\n\r\nAvro compatibility is provided using \"translators\" of Avro data:\r\n\r\n* AvroGenericToDataTranslator\r\n* DataMapToGenericRecordTranslator\r\n\r\nand Avro schemas:\r\n\r\n* SchemaTranslator - Translates Avro `Schema` to and from Pegasus `DataSchema`.\r\n\r\n\r\nValidation\r\n----------\r\n\r\nhttps://github.com/linkedin/rest.li/wiki/DATA-Data-Schema-and-Templates#data-to-schema-validation\r\n\r\n\r\nLicense\r\n-------\r\n\r\nCourier is [Apache 2.0 Licensed](LICENSE.txt).\r\n\r\nContributing\r\n------------\r\n\r\nFor development and submitting pull requests, please see the\r\n[Contributing document](CONTRIBUTING.md).","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}
